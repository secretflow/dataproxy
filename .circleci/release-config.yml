# Copyright 2024 Ant Group Co., Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

parameters:
  GHA_Action:
    type: string
    default: ""
  GHA_Actor:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""

executors:
  linux_x64_executor: # declares a reusable executor
    docker:
      - image: secretflow/release-ci:latest
    resource_class: 2xlarge+
    shell: /bin/bash --login -eo pipefail
  linux_aarch64_executor:
    docker:
      - image: secretflow/release-ci-aarch64:latest
    resource_class: arm.2xlarge
    shell: /bin/bash --login -eo pipefail
  macos_arm64_executor:
    macos:
      xcode: 15.1.0
    resource_class: macos.m1.large.gen1
  openjdk-executor-17:
    docker:
      - image: cimg/openjdk:17.0

commands:
  pip_publish:
    parameters:
      python_ver:
        type: string
    steps:
      - run:
          name: "build package and publish"
          command: |
            conda create -n build python=<< parameters.python_ver >> -y
            conda activate build

            python3 -m pip install twine

            cd dataproxy_sdk/python

            python setup.py bdist_wheel

            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} dist/*.whl

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  build-and-push:
    executor: openjdk-executor-17
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Build Jar
          command: make build
      - run:
          name: Push to Docker Hub
          command: |
            # login dataproxy dockerhub registry
            docker login -u ${DOCKER_DEPLOY_USERNAME} -p ${DOCKER_DEPLOY_TOKEN}
            # login dataproxy aliyun registry
            docker login -u ${ALIYUN_DOCKER_USERNAME} -p ${ALIYUN_DOCKER_PASSWORD}  secretflow-registry.cn-hangzhou.cr.aliyuncs.com
            CIRCLETAG=$(echo ${CIRCLE_TAG} | sed 's/v//')

            BUILDER_EXISTS=$(
              docker buildx inspect dataproxy_image_buildx >/dev/null 2>&1
              echo $?
            )

            if [ "$BUILDER_EXISTS" -eq 0 ]; then
              echo "existing buildx builder: dataproxy_image_buildx"
              docker buildx use dataproxy_image_buildx
            else
              echo "creating new buildx builder: dataproxy_image_buildx"
              docker buildx create --name dataproxy_image_buildx --use
            fi

            remote_image="secretflow-registry.cn-hangzhou.cr.aliyuncs.com/secretflow/dataproxy:latest"
            docker buildx build \
            --platform linux/arm64,linux/amd64 \
            --tag "${remote_image}" \
            -f ./build/Dockerfiles/dataproxy.Dockerfile . \
            --push

            remote_image="secretflow/dataproxy:latest"
            docker buildx build \
            --platform linux/arm64,linux/amd64 \
            --tag "${remote_image}" \
            -f ./build/Dockerfiles/dataproxy.Dockerfile . \
            --push

            remote_image="secretflow-registry.cn-hangzhou.cr.aliyuncs.com/secretflow/dataproxy:${CIRCLETAG}"
            docker buildx build \
            --platform linux/arm64,linux/amd64 \
            --tag "${remote_image}" \
            -f ./build/Dockerfiles/dataproxy.Dockerfile . \
            --push

            remote_image="secretflow/dataproxy:${CIRCLETAG}"
            docker buildx build \
            --platform linux/arm64,linux/amd64 \
            --tag "${remote_image}" \
            -f ./build/Dockerfiles/dataproxy.Dockerfile . \
            --push

  linux_sdk_publish:
    parameters:
      python_ver:
        type: string
      executor:
        type: string
    executor: <<parameters.executor>>
    steps:
      - checkout
      - pip_publish:
          python_ver: << parameters.python_ver >>

  macOS_sdk_publish:
    parameters:
      python_ver:
        type: string
      executor:
        type: string
    executor: <<parameters.executor>>
    steps:
      - checkout
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazelisk cmake ninja libomp wget go
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py310_24.1.2-0-MacOSX-arm64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init zsh bash
      - pip_publish:
          python_ver: << parameters.python_ver >>

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  publish:
    jobs:
      - linux_sdk_publish:
          matrix:
            parameters:
              python_ver: ["3.9", "3.10", "3.11"]
              executor: ["linux_x64_executor", "linux_aarch64_executor"]
          # This is mandatory to trigger a pipeline when pushing a tag
          filters:
            tags:
              only: /^v.*/
      - macOS_sdk_publish:
          matrix:
            parameters:
              python_ver: ["3.9", "3.10", "3.11"]
              executor: ["macos_arm64_executor"]
          # This is mandatory to trigger a pipeline when pushing a tag
          filters:
            tags:
              only: /^v.*/
      - build-and-push:
          filters:
            tags:
              only: /^v.*/
